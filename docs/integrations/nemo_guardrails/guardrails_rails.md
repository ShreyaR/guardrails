This guide will teach you how to add guardrails configurations built with NeMo Guardrails to your Guardrails AI application.

# Overview

The Guardrails AI library provides a Rails integration that allows you to use a Rails application as an LLM callable. This will result in a Rails application that generates completions that are validated using a GuardrailsAI guard configuration.

We start by defining a Guardrails AI Guard and a Rails configuration. We'll also install the [ToxicLanguage validator](https://hub.guardrailsai.com/validator/guardrails/toxic_language) from the [Guardrails AI Hub](https://hub.guardrailsai.com/).

```python
from nemoguardrails import LLMRails, RailsConfig
from guardrails import Guard, install

install("hub://guardrails/toxic_language")
from guardrails.hub import ToxicLanguage

# Load a guardrails configuration from the specified path.
config = RailsConfig.from_path("PATH/TO/CONFIG")
rails = LLMRails(config)
```

Then, we have the guard validate the completions generated by the Rails application.

```python
from guardrails.integrations.nemoguardrails.nemoguardrails_guard import (
    NemoguardrailsGuard
)
railsguard = NemoguardrailsGuards(rails).use(ToxicLanguage)

result = railsguard(
  messages: [{
    "role":"user",
    "content":"Hello! What can you do for me?"
  }]
)
```

The `NemoguardrailsGuard` class is a wrapper around the Guard class. Just like a Guard, it can [called](https://www.guardrailsai.com/docs/api_reference_markdown/guards#__call__) with similar parameters to the OpenAI completions API. It also returns a `ValidationOutcome` object (or iterable, in streaming cases). That object can be destructured to get the raw output, the validated output, and other metadata.

Here, `raw_llm_output` is the output returned by the NeMo Guardrails Rails.

```
result.raw_llm_output
result.validated_output
result.validation_passed
```

## Expected NeMo Guardrails Rails output

The NeMo Guardrails Rails may return any serializable type expressable in python using native types or Pydantic. The output must conform to the datatypes expected by the specified Guard. If the output is structured, make sure to initialize the Guardrails AI Guard using pydantic, [following this guide](https://www.guardrailsai.com/docs/how_to_guides/generate_structured_data).

# Integration with the NeMo Guardrails server

To wrap a call to the NeMo Guardrails server, we can leverage the OpenAI-style API endpoint available. We can talk to this endpoint directly through the Guard, setting the correct endpoint and config_id.


First, start the NeMo Guardrails server:

```bash
nemoguardrails server [--config PATH/TO/CONFIGS] [--port PORT]
```

Then, talk to it using the Guard:

```python
from guardrails import Guard
guard = Guard.use(
  ToxicLanguage()
)

# invoke the guard using the endpoint and config_id
guard(
  endpoint="http://localhost:8000/v1/chat/completions",
  config_id="CONFIG_ID",
  messages: [{
    "role":"user",
    "content":"Hello! What can you do for me?"
  }]
)
```
