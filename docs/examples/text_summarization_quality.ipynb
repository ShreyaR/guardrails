{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize text accurately\n",
    "\n",
    "!!! note\n",
    "    To download this example as a Jupyter notebook, click [here](https://github.com/ShreyaR/guardrails/blob/main/docs/examples/text_summarization_quality.ipynb).\n",
    "\n",
    "In this example, we will use Guardrails in the summarization of a text document. We will check whether the summarized document has a high semantic similarity with the original document.\n",
    "\n",
    "## Objective\n",
    "\n",
    "Summarize a text document and check whether the summarized document has a high semantic similarity with the original document.\n",
    "\n",
    "## Step 0: Setup\n",
    "\n",
    "In order to run this example, you will need to install the `numpy` package. You can do so by running the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create the RAIL Spec\n",
    "\n",
    "Ordinarily, we would create an RAIL spec in a separate file. For the purposes of this example, we will create the spec in this notebook as a string following the RAIL syntax. For more information on RAIL, see the [RAIL documentation](../rail/output.md).\n",
    "\n",
    "In this RAIL spec, we:\n",
    "\n",
    "1. Create an `output` schema that returns a single key-value pair. The key should be 'summary', and the value should be the summary of the given document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rail_str = \"\"\"\n",
    "<rail version=\"0.1\">\n",
    "\n",
    "<script language='python'>\n",
    "document = open(\"data/article1.txt\", \"r\").read()\n",
    "</script>\n",
    "\n",
    "<output>\n",
    "    <string\n",
    "        name=\"summary\"\n",
    "        description=\"Summarize the given document faithfully.\"\n",
    "        format=\"similar-to-document: ${document}, 0.60\"\n",
    "        on-fail-similar-to-document=\"filter\" \n",
    "    />\n",
    "</output>\n",
    "\n",
    "<prompt>\n",
    "Summarize the following document:\n",
    "\n",
    "${document}\n",
    "\n",
    "${gr.complete_json_suffix}\n",
    "</prompt>\n",
    "</rail>\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! note\n",
    "\n",
    "    In order to ensure the summary is similar to the document, we use `similar-to-document` as the validator. This validator embeds the document and the summary and checks whether the cosine similarity between the two embeddings is above a threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create a `Guard` object with the RAIL Spec\n",
    "\n",
    "We create a `gd.Guard` object that will check, validate and correct the output of the LLM. This object:\n",
    "\n",
    "1. Enforces the quality criteria specified in the RAIL spec.\n",
    "2. Takes corrective action when the quality criteria are not met.\n",
    "3. Compiles the schema and type info from the RAIL spec and adds it to the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import guardrails as gd\n",
    "\n",
    "from rich import print\n",
    "\n",
    "guard = gd.Guard.from_rail_string(rail_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the prompt that will be sent to the LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(guard.base_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `statement_to_be_translated` is the the statement and will be provided by the user at runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Wrap the LLM API call with `Guard`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's try translating a statement that doesn't have any profanity in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "raw_llm_response, validated_response = guard(\n",
    "    openai.Completion.create,\n",
    "    prompt_params={'document': open(\"data/article1.txt\", \"r\").read()},\n",
    "    engine='text-davinci-003',\n",
    "    max_tokens=2048,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(f\"Validated Output: {validated_response}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to see a detailed look into the logs of the `Guard` object, we can print the `Guard` state history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(guard.state.most_recent_call.tree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `guard` wrapper returns the raw_llm_respose (which is a simple string), and the validated and corrected output (which is a dictionary). We can see that the output is a dictionary with the correct schema and types.\n",
    "\n",
    "Next, let's try using a smaller model, which is not boing to be good at summarization. We can see that the output is filtered out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_llm_response, validated_response = guard(\n",
    "    openai.Completion.create,\n",
    "    prompt_params={'document': open(\"data/article1.txt\", \"r\").read()},\n",
    "    engine='text-ada-001',\n",
    "    max_tokens=512,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(f\"Validated Output: {validated_response}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the step-wise history of the `Guard` object below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(guard.state.most_recent_call.tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guardrails",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
