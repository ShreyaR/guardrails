{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Structured Synthetic Data\n",
    "\n",
    "!!! note\n",
    "    To download this tutorial as a Jupyter notebook, click [here](https://github.com/ShreyaR/guardrails/blob/main/docs/examples/generate_structured_data.ipynb).\n",
    "\n",
    "In this example, we'll generate structured dummy data for a `pandas` dataframe.\n",
    "\n",
    "We make the assumption that:\n",
    "\n",
    "1. We don't need any external libraries that are not already installed in the environment.\n",
    "2. We are able to execute the code in the environment.\n",
    "\n",
    "## Objective\n",
    "\n",
    "We want to generate structured synthetic data, where each column has a specific data type. All rows in the dataset must respect the column data types. Additionally, we have some more constraints we want the data to respect:\n",
    "\n",
    "1. There should be exactly 10 rows in the dataset.\n",
    "2. Each user should have a first name and a last name.\n",
    "3. The number of orders associated with each user should be between 0 and 50.\n",
    "4. Each user should have a most recent order date.\n",
    "\n",
    "\n",
    "## Step 1: Generating `RAIL` Spec\n",
    "\n",
    "Ordinarily, we could create a separate `RAIL` spec in a file. However, for the sake of this example, we will generate the `RAIL` spec in the notebook as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rail_str = \"\"\"\n",
    "<rail version=\"0.1\">\n",
    "\n",
    "<output>\n",
    "    <list name=\"user_orders\" description=\"Generate a list of user, and how many orders they have placed in the past.\" format=\"length: 10 10\" on-fail-length=\"noop\">\n",
    "        <object>\n",
    "            <string name=\"user_id\" description=\"The user's id.\" format=\"1-indexed\" />\n",
    "            <string name=\"user_name\" description=\"The user's first name and last name\" format=\"two-words\" />\n",
    "            <integer name=\"num_orders\" description=\"The number of orders the user has placed\" format=\"valid-range: 0 50\" />\n",
    "            <date name=\"last_order_date\" description=\"Date of last order\" />\n",
    "        </object>\n",
    "    </list>\n",
    "</output>\n",
    "\n",
    "\n",
    "<prompt>\n",
    "Generate a dataset of fake user orders. Each row of the dataset should be valid.\n",
    "\n",
    "${gr.complete_json_suffix}</prompt>\n",
    "\n",
    "</rail>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create a `Guard` object with the RAIL Spec\n",
    "\n",
    "We create a `gd.Guard` object that will check, validate and correct the generated code. This object:\n",
    "\n",
    "1. Enforces the quality criteria specified in the RAIL spec (i.e. bug free code).\n",
    "2. Takes corrective action when the quality criteria are not met (i.e. reasking the LLM).\n",
    "3. Compiles the schema and type info from the RAIL spec and adds it to the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import guardrails as gd\n",
    "\n",
    "from rich import print\n",
    "\n",
    "guard = gd.Guard.from_rail_string(rail_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Guard` object compiles the output schema and adds it to the prompt. We can see the final prompt below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(guard.base_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Wrap the LLM API call with `Guard`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "raw_llm_response, validated_response = guard(\n",
    "    openai.Completion.create, engine=\"text-davinci-003\", max_tokens=2048, temperature=0\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the cell above returns:\n",
    "1. The raw LLM text output as a single string.\n",
    "2. A dictionary where the key `user_orders` key contains a list of dictionaries, where each dictionary represents a row in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(validated_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(guard.state.most_recent_call.tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiff-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
