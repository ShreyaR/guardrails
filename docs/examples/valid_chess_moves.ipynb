{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing Valid Chess Moves\n",
    "\n",
    "!!! note\n",
    "    To download this example as a Jupyter notebook, click [here](https://github.com/ShreyaR/guardrails/blob/main/docs/examples/valid_chess_moves.ipynb).\n",
    "\n",
    "!!! warning\n",
    "    This example is currently under development (it cannot be used to play a full chess game yet).\n",
    "\n",
    "In this example, we will use Guardrails to play chess with an LLM and ensure that it makes valid moves.\n",
    "\n",
    "## Objective\n",
    "\n",
    "We want to generate a valid chess moves for a given board state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import guardrails as gd\n",
    "from rich import print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install chess"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create the RAIL Spec\n",
    "\n",
    "Ordinarily, we would create an RAIL spec in a separate file. For the purposes of this example, we will create the spec in this notebook as a string following the RAIL syntax. For more information on RAIL, see the [RAIL documentation](../rail/output.md).\n",
    "\n",
    "Here, we request:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rail_str = \"\"\"\n",
    "<rail version=\"0.1\">\n",
    "\n",
    "<script language='python'>\n",
    "from dataclasses import dataclass\n",
    "from guardrails.validators import Validator, EventDetail, register_validator\n",
    "\n",
    "import re\n",
    "from typing import Dict, List\n",
    "\n",
    "import chess\n",
    "\n",
    "BOARD = chess.Board()\n",
    "\n",
    "@register_validator(name=\"is-valid-chess-move\", data_type=\"string\")\n",
    "class IsValidChessMove(Validator):\n",
    "\n",
    "    board = BOARD\n",
    "\n",
    "    def validate(self, key, value, schema) -> Dict:\n",
    "        global BOARD\n",
    "        try:\n",
    "            # Push the move onto the board.\n",
    "            BOARD.push_san(value)\n",
    "        except Exception as e:\n",
    "            # If the move is invalid, raise an error.\n",
    "            raise EventDetail(\n",
    "                key,\n",
    "                value,\n",
    "                schema,\n",
    "                f\"Value {value} is not a valid chess move. {e}\",\n",
    "                None,\n",
    "            )        \n",
    "\n",
    "        return schema\n",
    "</script>\n",
    "\n",
    "\n",
    "<output>\n",
    "    <string description=\"A move in standard algebraic notation.\" name=\"move\" required=\"true\" format=\"is-valid-chess-move\" on-fail-is-valid-chess-move=\"reask\" />\n",
    "</output>\n",
    "\n",
    "\n",
    "<prompt>\n",
    "Generate a move for the chess board. The board is currently in the following state:\n",
    "${board_state}\n",
    "${gr.complete_json_suffix}\n",
    "</prompt>\n",
    "\n",
    "</rail>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create a `Guard` object with the RAIL Spec\n",
    "\n",
    "We create a `gd.Guard` object that will check, validate and correct the output of the LLM. This object:\n",
    "\n",
    "1. Enforces the quality criteria specified in the RAIL spec.\n",
    "2. Takes corrective action when the quality criteria are not met.\n",
    "3. Compiles the schema and type info from the RAIL spec and adds it to the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guard = gd.Guard.from_rail_string(rail_str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the prompt that will be sent to the LLM. The `{board_state}` is substituted with the current state of the board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(guard.base_prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the reference to the board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = guard.output_schema.move.validators[0].board\n",
    "board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Wrap the LLM API call with `Guard`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "raw_llm_response, validated_response = guard(\n",
    "    openai.Completion.create,\n",
    "    prompt_params={\n",
    "        \"board_state\": str(board.move_stack)\n",
    "        if board.move_stack\n",
    "        else \"Starting position.\"\n",
    "    },\n",
    "    engine=\"text-davinci-003\",\n",
    "    max_tokens=2048,\n",
    "    temperature=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `guard` wrapper returns the raw_llm_respose (which is a simple string), and the validated and corrected output (which is a dictionary).\n",
    "\n",
    "We can see that the output is a dictionary with the correct schema and types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(validated_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a move."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board.push_san(\"e5\")\n",
    "board"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ask for another move from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_llm_response, validated_response = guard(\n",
    "    openai.Completion.create,\n",
    "    prompt_params={\n",
    "        \"board_state\": str(board.move_stack)\n",
    "        if board.move_stack\n",
    "        else \"Starting position.\"\n",
    "    },\n",
    "    engine=\"text-davinci-003\",\n",
    "    max_tokens=2048,\n",
    "    temperature=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board.push_san(\"Nc6\")\n",
    "board"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiff-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef14f49bbc779f2fde64ca0552c2a99d578405052f5b73f61279551da311a8a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
